---
title: "Untitled"
author: "Hannah Swan"
date: "2024-12-02"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
rm(list=ls())
```

```{r}
library(tidyverse)
library(DESeq2)
library(Biostrings)
```

```{r}
source("/scratch/hswan/thesis_isomiR_count_denoising/load_mouse_miRNA_data_function.R")
source("/scratch/hswan/thesis_isomiR_count_denoising/correct_technical_length_variant_functions.R")
```

```{r}
mouse_data = load_mouse_miRNA_data()
rowdata = mouse_data$rowdata
countdata = mouse_data$countdata
```

```{r}
count_df = rowSums(countdata) 
count_df = cbind(rowdata, count=count_df) %>% data.frame()
head(count_df)

unique_miRNAs = unique(count_df$miRNA_name)
num_isomiRs = sapply(unique_miRNAs, function(x) filter(count_df, miRNA_name == x) %>% nrow())
num_isomiRs_freq = table(num_isomiRs)
x = names(num_isomiRs_freq) %>% as.numeric() %>% log()
plot(x, table(num_isomiRs), xlab = "Log of number of isomiRs", ylab="Number of miRNAs")
```

```{r}
x = num_isomiRs[num_isomiRs >= 50] %>% sort()
test_miRNA = names(x[1])
cat("Test miRNA:", test_miRNA)
#make initial partition
partition_df = filter(count_df, miRNA_name == test_miRNA)
partition_df$partition = rep(1, nrow(partition_df))
#id initial center sequence
initial_center_seq = filter(partition_df, count == max(count)) %>% select(., uniqueSequence) %>% unlist() %>% unname()
partition_df$center = rep(0, nrow(partition_df))
partition_df$center[partition_df$uniqueSequence == initial_center_seq] = 1

head(partition_df)
filter(partition_df, center == 1)
```

\n\n Now we're going to begin the partitoning, so we need the transition probabilities  matrix that we calculated 
```{r}
matrix_files = list.files("/scratch/hswan/thesis_isomiR_count_denoising/transition_count_matrices")
matrices = lapply(matrix_files, function(x) paste0("/scratch/hswan/thesis_isomiR_count_denoising/transition_count_matrices/", x) %>% readRDS())

c  = matrices[[1]]
for(i in 2:length(matrices)){
  c = c+matrices[[i]]
}

transition_probs = c
for(i in 1:nrow(c)){
  transition_probs[i,] = transition_probs[i,]/sum(transition_probs[i,])
}
cat("Transition probabilities:\n")
transition_probs
```

\n\n Now begin: first we need to get pairwise alignments between each isomiR sequence in partition and the center sequence
```{r}
isomiR_seqs = partition_df$uniqueSequence[partition_df$center == 0]
alignments = lapply(isomiR_seqs, Biostrings::pairwiseAlignment, pattern = initial_center_seq)
names(alignments) = isomiR_seqs
head(alignments)
```
\n\n From alignments get transitions
```{r}
transitions = lapply(alignments, get_transitions)
head(transitions, 3)
```
\n\n using transition object calculate lambdas
```{r}
lambdas = lapply(transitions, compute_lambda, transition_probs=transition_probs)
```

\n\n now compute abundance p-values using observed read counts and lambdas
```{r}
nj = filter(partition_df, center == 1) %>% select(., count) %>% unlist() %>% unname()
nis = filter(partition_df, center == 0) %>% select(., count) %>% unlist()
names(nis) = filter(partition_df, center == 0) %>% select(., uniqueSequence) %>% unlist() 
p = vector(length = length(nis))
names(p) = names(nis)
for(seq in isomiR_seqs){
  ni = nis[seq]
  lambda = lambdas[[seq]]
  num = ppois(ni-1, nj*lambda, lower.tail=F)
  denom = 1-dpois(0, nj*lambda)
  p[seq]=num/denom
}
#adjust for multiple testing 
adjusted_p = p.adjust(p, method='BH')
head(adjusted_p)
```
\n\n Now use abundance p-values to begin a new  partition
```{r}
significant_p = adjusted_p[adjusted_p < 0.05] 
new_center_seq = names(significant_p[significant_p == min(significant_p)])
#create copy of new partition for updating
update_df=partition_df
#create new partition
new_partition = max(update_df$partition)+1
update_df$center[update_df$uniqueSequence == new_center_seq] = 1
update_df$partition[update_df$uniqueSequence == new_center_seq] = new_partition

#update list of isomiR_seqs
isomiR_seqs = isomiR_seqs[isomiR_seqs != new_center_seq]
#now  we need to decide where the sequences with sigificant p-values should go
new_alignments = lapply(names(significant_p)[names(significant_p) != new_center_seq], Biostrings::pairwiseAlignment, pattern = new_center_seq)
names(new_alignments) = names(significant_p)[names(significant_p) != new_center_seq]
transitions = lapply(new_alignments, get_transitions)
new_lambdas = lapply(transitions, compute_lambda, transition_probs=transition_probs)

significant_seq = names(significant_p)[names(significant_p) != new_center_seq]
master_lambdas = list(lambdas, new_lambdas)
names(master_lambdas) = sort(unique(update_df$partition))
for(seq in significant_seq){
  l = lapply(master_lambdas, function(x) return(x[[seq]])) %>% unlist()
  new_p = names(l)[which(l == max(l))]
  update_df$partition[update_df$uniqueSequence==seq]=as.numeric(new_p)
}

table(update_df$partition)
#save partition_df as the updated object:
partition_df = update_df
```

## BEGIN SECOND ITERATION OF PARTITIONING

\n\n Now we have 2 partitions so things are going to work a little differently as we calculate the abundance p-values going forward

```{r}
unique_partitions = unique(partition_df$partition) %>% as.numeric() %>% sort()
cat("Unique partitons that we currently have:", unique_partitions, "\n")


#initialize abundance p-values 
p = vector(length=nrow(partition_df[partition_df$center==0,]))
names(p) = partition_df$uniqueSequence[partition_df$center == 0]
#iterate through partitions:
for(j in unique_partitions){
  nj = filter(partition_df, center==1 & partition == j) %>% select(., count)  %>% unlist() %>%  unname()
  cat("Partition:", j, "\n")
  cat("Observed read count of center sequence:", nj, "\n")
  partition_isomiRs=filter(partition_df, partition == j & center ==  0) %>% select(., uniqueSequence) %>% unlist()
  nis = filter(partition_df, uniqueSequence %in% partition_isomiRs) %>% select(., count) %>% unlist()
  names(nis) = partition_isomiRs
  #iterate through partition isomiRs:
  if(length(partition_isomiRs) != 0){
    for(i in partition_isomiRs){
      lambda = master_lambdas[[j]][[i]]
      ni = nis[[i]]
      num = ppois(ni-1, nj*lambda, lower.tail=F)
      denom = 1-dpois(0, nj*lambda)
      p[i] = num/denom
    }
  }
}

#adjust for multiple testing
adjusted_p = p.adjust(p, method="BH") 
results_df = data.frame("adjusted_p"=adjusted_p)

#now for each existing partition, determine if we need  to start a new partition
update_df=partition_df

for(j in unique_partitions){
  partition_isomiRs = filter(partition_df, center == 0 & partition == j) %>% select(., uniqueSequence) %>% unlist() %>% unname()
  significant_seq = adjusted_p[partition_isomiRs]
  significant_seq = significant_seq[significant_seq < 0.05]
  if(length(significant_seq) == 0){
    cat("do not need to create a new partition from partition", j, "\n")
  }
  else{
    new_center_seq = names(significant_seq)[significant_seq == min(significant_seq)]
    cat("New center seq:", new_center_seq, "\n")
    new_partition = max(as.numeric(update_df$partition)) + 1
    cat("Creating partition", new_partition, "from partiton", j, "\n")
    update_df$partition[update_df$uniqueSequence == new_center_seq] = new_partition
    update_df$center[update_df$uniqueSequence == new_center_seq] = 1
  }
}

filter(update_df, center == 1)

#now we need to decide where the sequences with significant p-values should go
significant_seq = filter(results_df, adjusted_p < 0.05) %>%  row.names()
significant_seq = significant_seq[!(significant_seq %in% update_df$uniqueSequence[update_df$center==1])]

#update list of unique partitions
unique_partitions = update_df$partition %>% as.numeric() %>% unique() %>% sort()
for(j in unique_partitions){
  cat(j, "\n")
  print(j %in% names(master_lambdas))
  if(!(j %in% names(master_lambdas))){
    center = update_df$uniqueSequence[update_df$center==1 & update_df$partition==j]
    cat("center sequence of partition", j, ":", center, "\n")
    new_alignments = lapply(significant_seq, Biostrings::pairwiseAlignment, pattern=center)
    names(new_alignments)=significant_seq
    new_transitions = lapply(new_alignments, get_transitions)
    new_lambdas = lapply(new_transitions, compute_lambda, transition_probs=transition_probs)
    master_lambdas[[length(master_lambdas)+1]] = new_lambdas
  }
}
names(master_lambdas) = unique_partitions

#update partition:

for(seq in significant_seq){
  l = lapply(master_lambdas, function(x) return(x[[seq]])) %>% unlist()
  new_p = names(l)[which(l == max(l))]
  update_df$partition[update_df$uniqueSequence==seq] = new_p
}
table(update_df$partition)
partition_df = update_df
```

### FUNCTION DEVELOPMENT
\n\n Now we need to write a function to do all this
The first step of the function is going to be initializing the appropriate partition_df object given the `rowdata`, the `count_df` object (an $i \times 1$ column vector) with one row for each unique sequence in the data and the element at position $i$ of the column vector being the sum of read counts across experiments for the $i^{th}$ sequence. Also takes transition probability matrix calculated outside of this function as an argument. 
```{r}

denoise_isomiR_counts = function(rowdata, count_df, transition_probability_matrix, miRNA, omega_A=NULL, max_iter = NULL, adjust_method=c("BH", "Bonferroni")){
  #initialize partition_df object 
  cat("Creating initial partition_df object for miRNA", miRNA, "\n")
  partition_df = cbind(rowdata, count=count_df) %>% data.frame() %>% filter(., miRNA_name == miRNA)
  partition_df$partition = rep(1, nrow(partition_df))
  partition_df$center = rep(0, nrow(partition_df))
  
  #id initial center sequence 
  initial_center_seq = filter(partition_df, count==max(count)) %>% select(., uniqueSequence) %>% unlist() %>% unname()
  
  partition_df$center[partition_df$uniqueSequence == initial_center_seq] = 1
  
  #with initial partition, complete 1st iteration outside of a while loop
  
  #STEP1 - get pairwise alignments between center sequence and all other sequences mapping to user-specified miRNA
  isomiR_seqs = partition_df$uniqueSequence[partition_df$center==0]
  cat("Getting initial alignments\n")
  alignments = lapply(isomiR_seqs, Biostrings::pairwiseAlignment, pattern=initial_center_seq)
  names(alignments) = isomiR_seqs
  cat("Getting initial transitions \n")
  transitions = lapply(alignments, get_transitions)
  cat("Calculating initial lambdas\n")
  lambdas = lapply(transitions, compute_lambda, transition_probs=transition_probability_matrix)
  master_lambdas = list(lambdas)
  names(master_lambdas) = 1 
  
  niter = 1
  no_change = 0 
  while(niter <= max_iter & no_change < 1){
    cat("Beginning iteration", niter, "\n")
    cat("Computing abundance p-values \n")
    unique_partitions = unique(partition_df$partition) %>% as.numeric() %>% sort()
    
    isomiR_seqs = partition_df$uniqueSequence[partition_df$center == 0]
    raw_p = vector(length = length(isomiR_seqs))
    names(raw_p) = isomiR_seqs
    
    for(j in unique_partitions){
      nj = filter(partition_df, partition == j & center == 1) %>% select(., count) %>% unlist() %>% unname()
      cat("Partition", j, "center has observed read sequence", nj, "\n")
      partition_isomiRs = filter(partition_df, partition == j & center == 0) %>% select(., uniqueSequence) %>% unlist() %>% unname()
      cat("Partition", j, "contains", length(partition_isomiRs), "non center sequences. \n")
      for(i in partition_isomiRs){
        #cat("seq:", i, "\n")
        ni = filter(partition_df, uniqueSequence == i) %>% select(., count) %>% unlist()
        #cat("lambda:",lambda, "\n")
        lambda = master_lambdas[[j]][[i]]
        num = ppois(ni-1, nj*lambda, lower.tail=FALSE)
        denom = 1-dpois(0, nj*lambda)
        #cat("Raw p-value:", num/denom, "\n")
        raw_p[i] = num/denom
        }
    }
    
    cat("Adjusting for multiple testing and getting hypothesis testing results \n")
    
    if(adjust_method == "BH"){
      adjusted_p = p.adjust(raw_p, method="BH")
      results = rep(0, length(adjusted_p))
      results[adjusted_p < omega_A] = 1
      results_df = cbind(raw_p=raw_p, adj_p=adjusted_p, sig = results) %>% data.frame()
    } else if(adjust_method == "Bonferroni"){
      results = rep(0, length(raw_p))
      results[raw_p < omega_A/length(results)] = 1
      results_df = cbind(raw_p=raw_p, sig = results) %>% data.frame()
    }
    
    #now we need to use the results to potentially ID a new center sequence for each existing partition
    
    #first - create copy of partition_df for updating 
    update_df = partition_df 
    
    for(j in unique_partitions){
      #for each partition, get list of partition isomiRs 
      partition_isomiRs = filter(partition_df, partition == j  & center == 0) %>% select(., uniqueSequence) %>% unlist() %>% unname()
      #create subset of hypothesis testing results for partition isomiRs 
      results_subset_df = results_df[partition_isomiRs,]
      # filter subset for significant p-values only if we have more than 0 rows in results_subset_df
       if(nrow(results_subset_df) > 0){
         new_center_seq = filter(results_subset_df, sig == 1) %>% filter(., adj_p==min(results_subset_df$adj_p)) %>% row.names()
         new_partition = max(update_df$partition) + 1 
         cat("Creating partition", new_partition, "from partition", j, ". Checking for new center sequence to  create partition. \n")
         if(length(new_center_seq) > 1){
           new_center_seq = sample(new_center_seq, 1)
         }
        update_df$partition[update_df$uniqueSequence == new_center_seq] = new_partition
        update_df$center[update_df$uniqueSequence == new_center_seq] = 1 
       }
    }
    
    #after IDing new center sequences / creating new partitions, we need to update our list of unique partitions and center sequences
    center_seqs = update_df$uniqueSequence[update_df$center == 1]
    
    #check to see if we've created any new partitions: 
    if(setequal(unique_partitions, unique(update_df$partition))==TRUE){
      cat("No new partitions created.\n")
      return(list(partition_df=partition_df, initial_center_seq=initial_center_seq, alignments=alignments, transitions=transitions, results_subset_df=results_subset_df, raw_p=raw_p, results_df=results_df, master_lambdas=master_lambdas, niter=niter, no_change=no_change, update_df=update_df))
    }
    
    unique_partitions = unique(update_df$partition) %>% as.numeric() %>% sort()
    
    #get list of sequences with significant p-values so we can consider those sequences for new group membership
    
    significant_seqs = row.names(results_df[results_df$sig==1,])
    significant_seqs = significant_seqs[!(significant_seqs %in% center_seqs)]
    
    for(j in unique_partitions){
      if(!(j %in% names(master_lambdas))){
        center_seq = filter(update_df, partition == j & center == 1) %>% select(., uniqueSequence) %>% unlist() %>% unname()
        new_alignments = lapply(significant_seqs, Biostrings::pairwiseAlignment, pattern = center_seq)
        names(new_alignments) = significant_seqs
        new_transitions = lapply(new_alignments, get_transitions)
        new_lambdas = lapply(new_transitions, compute_lambda, transition_probs = transition_probability_matrix)
        master_lambdas[[length(master_lambdas)+1]] = new_lambdas
      }
    }
    names(master_lambdas) = unique_partitions
    
    #now we need to determine which partition significant sequences are joining 
    
    for(i in significant_seqs){
      l = lapply(master_lambdas, function(x) return(x[[i]])) %>% unlist()
      new_p = names(l[which(l==max(l))]) %>% as.numeric()
      if(length(new_p) > 1){
        new_p = sample(new_p, 1)
      }
      update_df$partition[update_df$uniqueSequence == i] = new_p
    }
    
    cat("Finishing iteration", niter, "\n")
    niter = niter+1
    partition_df=update_df
  }
  #return everything we can rn because we're in the development stages (ugh lol)
  return(list(partition_df=partition_df, initial_center_seq=initial_center_seq, alignments=alignments, transitions=transitions, results_subset_df=results_subset_df, raw_p=raw_p, results_df=results_df, master_lambdas=master_lambdas, niter=niter, no_change=no_change, update_df=update_df))
}


```


```{r}
i = vector()
print(i)
for(num in i){
  print(num)
}
```

```{r}
count_df=rowSums(countdata)
tst = denoise_isomiR_counts(rowdata, count_df, transition_probs, test_miRNA, 0.05, 1, "BH")
tst_3_iterations = denoise_isomiR_counts(rowdata, count_df, transition_probs, test_miRNA, 0.05, 3, "BH")
tst_5_iterations = denoise_isomiR_counts(rowdata, count_df, transition_probability_matrix = transition_probs, test_miRNA, 0.05, 5, "BH")
tst_6 = denoise_isomiR_counts(rowdata, count_df, transition_probability_matrix = transition_probs, test_miRNA, 0.05, 6, "BH")
```

#ID new test miRNA and test function
```{r}
test_miRNA_2 = names(num_isomiRs[num_isomiRs >= 100  & num_isomiRs < 200][1])
cat("Test miRNA #2:", test_miRNA_2, "\n")

tst_miRNA_2 = denoise_isomiR_counts(rowdata, count_df, transition_probability_matrix = transition_probs, test_miRNA_2, 0.05, 1, "BH")
tst_miRNA_2_5_iterations = denoise_isomiR_counts(rowdata, count_df, transition_probability_matrix=transition_probs, test_miRNA_2, 0.05, 5, "BH")
tst_miRNA_2_10_iterations = denoise_isomiR_counts(rowdata, count_df, transition_probability_matrix=transition_probs, test_miRNA_2, 0.05, 10, "BH")
```



\n\n figuring out what the hell is going on with my function now 
```{r}
tst_5_iterations$master_lambdas %>% tibble()
tst_5_iterations$partition_df$partition %>% table()

partition_df = tst_3_iterations$partition_df

isomiR_seqs = partition_df$uniqueSequence[partition_df$center == 0]
p_values = vector(length = length(isomiR_seqs))
names(p_values) = isomiR_seqs

unique_partitions = partition_df$partition %>% as.numeric() %>% unique() %>% sort()
for(j in unique_partitions){
  nj = filter(partition_df, partition == j & center == 1) %>% select(., count) %>% unlist() %>% unname()
  cat("Partition", j, "center sequence has observed read count", nj, "\n")
  partition_isomiRs = filter(partition_df, center == 0 & partition == j) %>% select(., uniqueSequence) %>% unlist()
  cat("Partition", j, "contains", length(partition_isomiRs), "non-center sequences.\n")
  for(i in partition_isomiRs){
    ni = filter(partition_df, uniqueSequence == i) %>% select(., count) %>% unlist() %>% unname()
    lambda = tst_3_iterations$master_lambdas[[j]][[i]]
    num = ppois(ni-1, lambda*nj, lower.tail=F) 
    denom = 1-dpois(0, lambda*nj)
    p_values[i] = num/denom
  }
}

results_df = cbind(raw_p=p_values, seq=names(p_values)) %>% data.frame()
row.names(results_df) = NULL
results_df = cbind(adj_p=p.adjust(p_values, method="BH"), results_df)
results_df$sig = rep(0, nrow(results_df))
results_df$sig[results_df$adj_p < 0.05] = 1

for(j in unique_partitions){
  cat(j, "\n")
  partition_isomiRs = filter(partition_df, partition == j & center == 0) %>% select(., uniqueSequence) %>% unname() %>% unlist()
  if(length(partition_isomiRs) > 0){
    cat("Partition", j, "has", length(partition_isomiRs), "non center sequences.\n")
    new_center_seq = filter(results_df, seq %in% partition_isomiRs) %>% filter(., sig == 1) %>% filter(., adj_p == min(adj_p)) %>% select(., seq) %>% unlist()
    cat("New center seq from partition", j, "is", new_center_seq)
  }
  else{
    cat("No center sequences to be identified in partition", j, "\n")
  }
}
```
