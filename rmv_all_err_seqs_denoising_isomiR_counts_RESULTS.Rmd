---
title: "Remove all error sequences results"
author: "Hannah Swan"
date: "December 5, 2024"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F)
```

```{r}
source("/scratch/hswan/thesis_isomiR_count_denoising/denoise_isomiR_counts_WORKING_FUNCTION.R")
```

Okay note: the dollar sign weirdness are how things are showing up in the rowdata from Ernesto so it has something to do with how he processed the data. Is not because you named the files in a weird way or anything.
```{r}
mousedata = load_mouse_miRNA_data()
rowdata = mousedata$rowdata
countdata=mousedata$countdata
count_df = rowSums(countdata)
transition_probs = readRDS("/scratch/hswan/thesis_isomiR_count_denoising/transition_probs.Rds")
```


```{r}
unique_miRNAs = unique(rowdata$miRNA_name)
cat("There are", length(unique_miRNAs), "unique miRNAs in Ernesto's benchmark dataset.\n")
file_paths = list.files("/scratch/hswan/thesis_isomiR_count_denoising/rmv_all_err_seqs")
file_paths = file_paths[file_paths != "results"]
cat("Algorithm ran successfully for", length(file_paths), "unique miRNAs")
```

\n
\n

Don't need to evaluate this part because right now the functions are returning a lot of things in list format and we also have a lot of them, so loading them all takes a lot of memory. Already extracted what we want from them and wrote them to different .Rds files. \n\n
```{r, eval=FALSE}

files = list.files("/scratch/hswan/thesis_isomiR_count_denoising/rmv_all_err_seqs") %>% unlist()
files[1]

#get the files for miRNAs that attempted to have all error sequences removed 

#load partition_obj from all these files:
partition_obj_1 = paste0("/scratch/hswan/thesis_isomiR_count_denoising/rmv_all_err_seqs/", files[[length(files)]], collapse="") %>% readRDS()

miRNA = partition_obj_1$partition_df$miRNA_name[1]
cat("Partition obj for miRNA,", miRNA, "\n")

cat("Partitioning algorithm ran for", partition_obj_1$niter-1, "iterations \n")

cat("Partitions and the amount of sequences in each one:\n")
table(partition_obj_1$partition_df$partition)

cat("Center sequence of each partition and associated observed read count across all samples \n")
filter(partition_obj_1$partition_df, center == 1)


```

## Load all partition objects 
Ok i take it back this is too big and we end up crashing R will load on an as needed basis  
```{r, eval=FALSE}
file_paths = sapply(files, function(x) paste0("/scratch/hswan/thesis_isomiR_count_denoising/rmv_all_err_seqs/", x)) 
partition_objs = lapply(file_paths, readRDS)
```

#Get the things we're going to need
```{r, eval=FALSE}
partitions = lapply(partition_objs, function(x) return(x$partition_df))
names(partitions) = sapply(partitions, function(x) return(x$miRNA_name[1]))
num_iters_ran = lapply(partition_objs, function(x) return(x$niter))
rm(partition_objs)

saveRDS(partitions, "/scratch/hswan/thesis_isomiR_count_denoising/rmv_all_err_seqs/results/partition_results.Rds")
saveRDS(num_iters_ran, "/scratch/hswan/thesis_isomiR_count_denoising/rmv_all_err_seqs/results/num_iters_ran.Rds")
```

```{r, echo=TRUE}
partitions = readRDS("/scratch/hswan/thesis_isomiR_count_denoising/rmv_all_err_seqs/results/partition_results.Rds")
num_iters_ran = readRDS("/scratch/hswan/thesis_isomiR_count_denoising/rmv_all_err_seqs/results/num_iters_ran.Rds") %>% unlist() %>% unname()
```


\n\
\n 
For each partition object, get the number of iterations it ran for 
```{r}
cat("Number of iterations run to remove all error sequences:\n")
table(num_iters_ran)
cat("Mean number of iterations run to remove all error sequences:", mean(num_iters_ran), "\n")
```
\n
\n
Make a plot of the distribution of number of iterations ran: 
```{r}
library(ggplot2)
ggplot2::ggplot(data.frame(num_iters_ran), aes(x=num_iters_ran)) + geom_histogram() + ggplot2::xlab("number of iterations ran to remove all error seqs") + ylab("number of miRNAs") + ggplot2::ggtitle("Number of iterations used to remove all error sequences for all miRNAs")
```
\n
Also, it's important to note that to remove all the error sequences without ending the loop prematurely, we gave a large number of maximum iterations just to make sure that the function does stop eventually. For each miRNA, the algorthim was run with a maximum number of iterations equal to 100. The maximum number of iterations we ran to remove all the error sequences is 18, which I think is a good sign. It means even when we give the method a lot of freedom (large number of maximum iterations, stopping criteria is that no sequences move partitions) it still reaches the stopping point. 

\n\n Also for each partition, get the number of partitions created
```{r}
num_partitions = lapply(partitions, function(x) return(max(x$partition))) %>% unlist()
cat("Number of true isomiR sequences identified for each miRNA \n")
table(num_partitions)
```

\n
Make a plot of the number of partitions created:
```{r}
ggplot(data.frame(num_partitions), aes(x=num_partitions)) + geom_histogram() + ggtitle("Distribution of number of partitions detected by our method")
```

Definitely skewed towards creating a small number of partitions, which makes sense because we're assuming that true isomiR sequences are rare. Some miRNAs have more than 750 partitions being created. That might sound like a lot and maybe a cause for concern, but at the same time some miRNAs have 10s of 1000s of sequences mapping to them so it's not an immediate cause for concern. 

\n\n Also curious what the proportion of true isomiR sequences identified by our method to the total number of sequences mapping to that miRNA is. I think this might be a better metric for helping us evaluate performance because of the comment above. You might see a large number of partitions being created for a certain miRNA and think that its cause for alarm because it looks like the performance violates our assumption that true isomiRs are rare. As long as the only miRNAs where we see the proportion of true isomiR sequences to total number of sequences mapping to that miRNA is 1 are miRNAs where we only have 1 sequence mapping to that miRNA, we're okay at this point.
```{r}
prop_true_isomiR = vector(length=length(partitions))
for(i in 1:length(partitions)){
  num = max(partitions[[i]]$partition)
  denom = nrow(partitions[[i]])
  prop_true_isomiR[i] = num/denom
}



head(prop_true_isomiR)
cat("Minimum proportion of true isomiR sequences identified:", min(prop_true_isomiR), "\n")

#makes sense that in some cases the proportion of true isomiR sequences identified would be 1 - the case where we would expect this is when there is only 1 sequence mapping to a given miRNA. As long as this is the only case where that happens, I think we're okay 
cat("Maximum proportion of true isomiR sequences identified:", max(prop_true_isomiR), "\n")
```

```{r}
ggplot(data.frame(prop_true_isomiR), aes(x=prop_true_isomiR)) + geom_histogram() + ggtitle("Distribution of proportion of true isomiRs detected by our method")
```

\n
\n


```{r}
unique_miRNAs = unique(rowdata$miRNA_name)
num_seqs_mapped = sapply(unique_miRNAs, function(x) filter(rowdata, miRNA_name ==x) %>% nrow())
miRNA = num_seqs_mapped[num_seqs_mapped >= 10] %>% sort() %>% names()
miRNA = miRNA[1]

```


## Examining miRNAs where every unique sequence has been identified as a true isomiR
\n  
\n
Is there a good reason for this? One reason we see this is that there is only 1 sequence mapping to that miRNA as mentioned above. Sort of a weird edge case. Another thing that can happen is that we have a low read count for a small number of sequences. E.g. suppose we have 3 unique sequences mapping to a miRNA with observed read counts $y_1 = 2, y_2 = 2, y_3 =3$. Initially we will create 1 partition with sequence 3 being the center sequence. But because we have such small read counts, it looks like we have, say, a degradation rate of $2/3$ in comparison to a much smaller degradation rate according to the transition probability matrix. Therefore, each sequence will likely get its own partition. Is this valid? 
```{r}
all_seqs_true_isomiRs_miRNA = vector()

for(i in 1:length(partitions)){
  num_partitions = max(partitions[[i]]$partition)
  num_seqs = nrow(partitions[[i]])
  if(num_partitions == num_seqs){
    all_seqs_true_isomiRs_miRNA = c(all_seqs_true_isomiRs_miRNA, names(partitions)[i])
  }
}

all_seqs_true_isomiRs_num_seqs_mapped = sapply(all_seqs_true_isomiRs_miRNA, function(x) return(partitions[[x]] %>% nrow()))
names(all_seqs_true_isomiRs_num_seqs_mapped) =  all_seqs_true_isomiRs_miRNA

all_seqs_true_isomiRs_num_seqs_mapped %>% table()

for(i in 1:6){
  miRNA = all_seqs_true_isomiRs_miRNA[i]
  cat("miRNA:", miRNA, "\n")
  print(partitions[[miRNA]])
}

```

```{r, echo=TRUE}
cat("Testing function with Bonferroni adjustment for miRNA", miRNA, "\n")

tst = denoise_isomiR_counts(rowdata, count_df, transition_probs, miRNA, 0.05, 5, "Bonferroni")
tst_BH = denoise_isomiR_counts(rowdata, count_df, transition_probs, miRNA, 0.05, 5, "BH")
```

\n\n Compare the 2
```{r}
cat("Bonferroni:\n")
table(tst$partition_df$partition)
cat("Benjamini-Hochberg:\n")
table(tst_BH$partition_df$partition)
```
\n
\n 
So same number of partitions results from using both methods for adjusting for multiple testing. 

\n
\n 
Number of iterations run for both:
```{r}
cat("Algorithm with Bonferroni adjustment for multiple testing ran for:", tst$niter-1, "iterations\n")
cat("Algorithm with Benjamini-Hochberg adjustment for multiple testing ran for:", tst_BH$niter-1, "iterations \n")

cat("Do we end up with the exact same partitions from the two methods?\n")
if(all.equal(tst$partition_df$partition, tst_BH$partition_df$partition) == TRUE){
  cat("Yes\n")
}
```


Curious about the relationship to other center sequences that we have. How different is a newly identified center sequence from the center of its partition? 
```{r, echo=TRUE}
#take first partitions object
partition_df = partitions[[1]]

#take center sequence of first partition
center_seq = filter(partition_df, partition == 1 & center == 1) %>% select(., uniqueSequence) %>% unlist() %>% unname()

#take other center sequences: 
seqs = filter(partition_df, partition != 1 & center==1) %>% select(., uniqueSequence) %>% unlist() %>% unname()

a = pairwiseAlignment(pattern=center_seq, seqs[4])
print(a)
t = get_transitions(a)

#initialize different variables  for describing relationship between 2 seqs
num_subs = 0
num_dels = 0
num_ins = 0

for(i in 1:ncol(t)){
  trns = get_transition_at_idx(i, t)
  x = trns$x
  y = trns$y
  if(x == "-" & y != "-"){
    num_ins = num_ins +1
  } else if(x != "-" & y == "-"){
    num_dels = num_dels + 1 
  } else if(x != "-"  & y != "-" & x != y){
    num_subs = num_subs + 1 
  }
}

cat("Number of substitutions:", num_subs, "\n")
cat("Number of insertions:", num_ins, "\n")
cat("Number of deletions", num_dels, "\n")
```
\n 
\n 
Small number of sequences mapping to this miRNA so we can look at all rows in the partition_df object
```{r}
tst$partition_df

```

Look at the sequences and the alignments in each partition - are length variants / mixed type isomiRs more likely to get their own partition while sequence variants are more likely to stay in the same partition? 

```{r, evaluate=FALSE}
# #look at partition 1 - 
# part_1_subset = filter(tst$partition_df, partition == 1) 
# 
# Biostrings::pairwiseAlignment(pattern = part_1_subset$uniqueSequence[part_1_subset$center==1], part_1_subset$uniqueSequence[1])
# Biostrings::pairwiseAlignment(pattern = part_1_subset$uniqueSequence[part_1_subset$center==1], part_1_subset$uniqueSequence[2])
# Biostrings::pairwiseAlignment(pattern = part_1_subset$uniqueSequence[part_1_subset$center==1], part_1_subset$uniqueSequence[3])
# 
# lambda = tst$master_lambdas[[1]][[part_1_subset$uniqueSequence[3]]]
# nj = part_1_subset$count[part_1_subset$center == 1]
# ni = part_1_subset$count[part_1_subset$uniqueSequence== part_1_subset$uniqueSequence[3]]
# 
# #note that the following 2 lines are equivalent and dividing 1 by the other will always give 1. So we will never give a singleton sequence it's own partition under this model 
# ppois(0, nj*lambda, lower.tail=F)
# 1-dpois(0, nj*lambda)
# 
# #look at pairwise alignments between initial center sequence and the other center sequences: 
# center_seqs = tst$partition_df %>% filter(., center == 1) %>% select(., uniqueSequence) %>% unlist()
# initial_center_seq = tst$initial_center_seq
# center_seqs = center_seqs[center_seqs != initial_center_seq]
# 
# Biostrings::pairwiseAlignment(pattern = initial_center_seq, center_seqs[1])
# Biostrings::pairwiseAlignment(pattern = initial_center_seq, center_seqs[2])
# Biostrings::pairwiseAlignment(pattern = initial_center_seq, center_seqs[3])
```

Does the length of the center sequence decrease as the partition being created increases?
```{r}
#get unique partitions:
unique_partitions = unique(partitions[[1]]$partition) %>% sort()
center_sequence_length = sapply(unique_partitions, function(x) return(filter(partitions[[1]], partition == x) %>% filter(., center == 1) %>% select(., uniqueSequence) %>% unlist() %>% nchar()))
df = data.frame(x=unique_partitions, y=center_sequence_length)
ggplot(df, aes(x=x, y=y)) + geom_point() + geom_abline(slope=0, intercept = 20, col="red") +  ggplot2::xlab("unique partition") + ggplot2::ylab("length of center sequence")
```

It doesn't really look like there's any pattern here, which is good. \n\n

Is there a relationship between the observed read count of center sequences identified later and the partition being created?
```{r}
center_seq_obs_read_count = sapply(unique_partitions, function(x) filter(partitions[[1]], center==1 & partition==x) %>% select(., count) %>% unlist() %>% unname())
head(center_seq_obs_read_count)
df = data.frame(x=unique_partitions, y=log(center_seq_obs_read_count))
ggplot(df, aes(x=x,y=y)) + geom_point() + geom_abline(slope=-0.20, intercept = 8, col='red') + ggplot2::xlab("unique partition") + ggplot2::ylab("log of center sequence observed read count")
```
\n\n It does look like there is a decreasing trend here - as we move into later iterations we're selecting center sequences with smaller observed read counts. This is just for one miRNA but we likely see it in others as well: 

```{r, echo=T}
partition_df = partitions[[2]]
cat("Unique partitions created for miRNA", partition_df$miRNA_name[1], "\n")

unique_partitions = unique(partition_df$partition) %>% sort()
cat("According to our model, there are unique", max(unique_partitions), "isomiR sequences mapping to this miRNA.\n")
cat("There are", nrow(partition_df), "total sequences mapping to this miRNA")

#look at distribution of read counts:
y = table(partition_df$count)
x = as.numeric(names(y))
plot(x,y)

#look at observed read counts of center sequences 
filter(partition_df, center == 1) %>% select(., count) %>% unlist() %>% table()

#look at center sequences of the first 4 partitions
filter(partition_df, center == 1)

seq1 = filter(partition_df, center == 1 & partition == 1) %>% select(., uniqueSequence) %>% unlist() %>% unname()
seq2 = filter(partition_df, center == 1 & partition ==2) %>% select(., uniqueSequence) %>% unlist() %>% unname()

#seq2 is a templated length variant isomiR, missing 5 nucleotides off the 3' end 
#obs read count is in the thousands - does it make biological sense to treat this as its own sequence? would the seed sequence shift? or is this a product of degradation in the sample and we should handle separately to keep in 1st partition? 
Biostrings::pairwiseAlignment(pattern=seq1, seq2)
seq3 = filter(partition_df, center == 1 & partition ==3) %>% select(., uniqueSequence) %>% unlist()
Biostrings::pairwiseAlignment(pattern=seq1, seq3)
```

\n\n Curious if we use Bonferroni to adjust for multiple testing if we will see a decrease in the number of sequences with only a few reads being given their own partition 
```{r}
miRNA = partitions[[1]]$miRNA_name[1]

tst = denoise_isomiR_counts(rowdata, count_df, transition_probs, miRNA, 0.05, 10, "Bonferroni")

center_seq_counts = tst$partition_df %>% filter(., center == 1) %>% select(., count) %>% unlist()
cat("Number of partitions with a center sequence that has obs read count less than 50:", sum(center_seq_counts < 50), "\n")
cat("Total number of partitions:", max(tst$partition_df$partition), "\n")

filter(tst$partition_df, center ==1 & count <50)
filter(tst$partition_df, partition <= 16 & center == 1)
```