---
title: "EM Update Development to isomiR denoising function"
author: "Hannah Swan"
date: "November 7, 2024"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Step 0: Load necessary packages and Ernesto's benchmark dataset
```{r}
rm(list=ls())

library(Biostrings)
library(tidyverse)
library(DESeq2)

source("/scratch/hswan/thesis_isomiR_count_denoising/correct_technical_length_variant_functions.R")

#function to load Ernesto's benchmark dataset because I'm tired of typing these lines of code over and over lol
load_mouse_miRNA_data = function(){
  load("/scratch/mmccall2_lab/miRNA_reference/Rdata/summarized_experiment_isomiR.RData")
  isomiR_se_object = se_object
  rm(se_object)
  countdata = isomiR_se_object@assays@data$counts  %>% data.frame()
  colnames(countdata) = str_remove_all(colnames(countdata), "X")
  rowdata = rowData(isomiR_se_object) %>% data.frame()
  colnames(rowdata) = c("uniqueSequence", "miRNA_name")
  return(list(isomiR_se_object=isomiR_se_object, rowdata=rowdata, countdata=countdata))
}

data = load_mouse_miRNA_data()

isomiR_se_object=data$isomiR_se_object
countdata=data$countdata
rowdata=data$rowdata

```

Then select a test miRNA
```{r}
unique_miRNAs=unique(rowdata$miRNA_name) %>% as.character() %>% data.frame() 
colnames(unique_miRNAs) = "miRNA_name"
unique_miRNAs$num_isomiRs = sapply(unique_miRNAs$miRNA_name, function(x) return(filter(rowdata, miRNA_name == x) %>% nrow() %>% unlist()))
unique_miRNAs$count = sapply(unique_miRNAs$miRNA_name, function(x) return(cbind(rowdata, count=countdata[,2]) %>% filter(., miRNA_name == x) %>% select(., count) %>% unlist() %>% sum()))

head(unique_miRNAs)
potential_test_miRNAs = filter(unique_miRNAs, num_isomiRs < 1000) %>% filter(., count >= 500) %>% select(., miRNA_name) %>% unlist() %>% as.character()
test_miRNA = potential_test_miRNAs[2]

cat("Test miRNA is", test_miRNA, "\n")
```

# Step 0a: Creating a function that initializes the partition_df object for our algorithm 
```{r}
initialize_partition_df = function(miRNA, rowdata, countdata, sample_idx){
  partition_df = cbind(rowdata, count=countdata[,sample_idx]) %>% data.frame() %>% filter(., miRNA_name == miRNA)
  colnames(partition_df) = c("uniqueSequence", "miRNA_name", "count")
  
  uniq_isomiRs = unique(partition_df$uniqueSequence)
  for(i in uniq_isomiRs){
    row_idxs = which(partition_df$uniqueSequence == i)
    if(length(row_idxs) > 1){
    counts = partition_df$count[row_idxs]
    #keep only first instance:
    partition_df = partition_df[-row_idxs[-1],]
    partition_df$count[row_idxs[1]] = sum(counts)
    }
  }
  
  partition_df$partition = rep(1, nrow(partition_df))
  partition_df$center = rep(0, nrow(partition_df))
  initial_center_seq = filter(partition_df, count == max(count)) %>% select(., uniqueSequence) %>% unlist() %>% unname()
  initial_center_seq = initial_center_seq[1]
  partition_df$center[partition_df$uniqueSequence == initial_center_seq] = 1
  return(partition_df)
}

initial_partition_df = initialize_partition_df(test_miRNA, rowdata, countdata, 2)
```

# Step a: Transition probability estimation for initial partition
```{r}
estimate_transition_probs = function(partition_df){
  uniq_partitions = unique(partition_df$partition)
  alignments = list()
  for(j in uniq_partitions){
    center_seq = filter(partition_df, partition == j & center ==1) %>% select(., uniqueSequence) %>% unlist() %>% unname()
    partition_isomiRs = filter(partition_df, partition == j & center == 0 & count !=0) %>% select(., uniqueSequence) %>% unlist() %>% unname()
    a = lapply(partition_isomiRs, Biostrings::pairwiseAlignment, pattern = center_seq)
    names(a) = partition_isomiRs
    alignments = c(alignments, a)
  }
  transitions = lapply(alignments, get_transitions)
  transition_counts = initialize_transition_counts_matrix(5)
  for(t in transitions){
    alignment_length = ncol(t)
    for(i in 1:alignment_length){
      trns = get_transition_at_idx(i, t)
      x=trns$x
      y=trns$y
      if(i == 1 & x != "-" & y != "-"){
        transition_counts["-", "-"] = transition_counts["-", "-"]+1
        transition_counts[x,y] = transition_counts[x,y] + 1
      }
      if(i == alignment_length & x != "-" & y != "-"){
        transition_counts["-", "-"] = transition_counts["-", "-"]+1
        transition_counts[x,y] = transition_counts[x,y] + 1
      }
      else{
        transition_counts[x,y] = transition_counts[x,y] + 1
      }
    }
    transition_probs = transition_counts 
    for(i in 1:nrow(transition_probs)){
      transition_probs[i,] = transition_probs[i,]/sum(transition_probs[i,])
    }
  }
  return(transition_probs)
}



```

### Step b: Partitioning using estimated transition_probs matrix
```{r}
transition_probs = estimate_transition_probs(initial_partition_df)
estimate_isomiR_partition_membership = function(partition_df, transition_probs, max_iter_partitioning, OMEGA_A){
  #initialize 2 variables we will use to decide when to stop grouping 
  iter_partitioning = 0 
  no_change = 0 
  #ID center sequences
  center_seqs = filter(partition_df, center == 1) %>% select(., uniqueSequence) %>% unlist() %>% unname()
  #ID isomiR sequences 
  isomiR_seqs = filter(partition_df, center == 0 & count !=0) %>% select(., uniqueSequence) %>% unlist() %>% unname()
  
  #initialize master_lambdas list
  master_lambdas = list()
  while(iter_partitioning < max_iter_partitioning & no_change == 0){
    #get unique_partitions 
    uniq_partitions = unique(partition_df$partition)
    if(length(uniq_partitions) == 1){
      cat("Getting alignments \n")
      alignments = lapply(isomiR_seqs, Biostrings::pairwiseAlignment, pattern = center_seqs)
      names(alignments) = isomiR_seqs
      cat("Getting transitions from alignments \n")
      transitions=lapply(alignments, get_transitions)
      cat("Calculating lambdas from transitions \n")
      lambdas = lapply(transitions, compute_lambda, transition_probs=transition_probs)
      master_lambdas[[center_seqs]] = lambdas
      n_j = filter(partition_df, uniqueSequence == center_seqs) %>% select(., count) %>% unlist() %>% unname()
      cat("Observed read count of center of only partition is", n_j, "\n")
      cat("Calculating abundance p-values \n")
      n_is = sapply(isomiR_seqs, function(x) return(filter(partition_df, uniqueSequence ==x) %>% select(., count) %>% unlist() %>% unname()))
      names(n_is) = isomiR_seqs
      raw_p_values = vector()
      for(i in isomiR_seqs){
        n_i = n_is[[i]]
        lambda = lambdas[[i]]
        num = ppois(n_i, n_j * lambda, lower.tail=FALSE)
        denom = 1-dpois(0, n_j*lambda)
        p = c(num/denom)
        names(p)=i
        raw_p_values = c(raw_p_values, p)
      }
      results_df = data.frame(raw_p_values)
      cat("Adjusting p-values for multiple testing \n")
      results_df$adjusted_p_values = p.adjust(results_df$raw_p_values, method = "BH")
      results_df$significant = rep(0, nrow(results_df))
      results_df$significant[results_df$adjusted_p_values < OMEGA_A] = 1
      
      cat("Determining if we need to create any new partitions \n")
      significant_seqs = row.names(results_df)[results_df$significant == 1]
      
      #if at least 1 significant sequence, then we create a new partition and ID a new center sequence 
      if(length(significant_seqs) > 0){
        #create a copy of partition_df for updating 
        update_df = partition_df
        for(j in uniq_partitions){
          partition_isomiRs = filter(partition_df, center == 0 & count != 0 & partition == j) %>% select(., uniqueSequence) %>% unlist() %>% unname()
          significant_partition_isomiRs = partition_isomiRs[partition_isomiRs %in% significant_seqs]
          if(length(significant_partition_isomiRs) > 0){
            #ID new center sequence 
            new_center_seq = filter(partition_df, uniqueSequence %in% significant_partition_isomiRs) %>% filter(., count == max(count)) %>% select(., uniqueSequence) %>% unlist() %>% unname()
            new_center_seq = new_center_seq[1]
            #create new grp
            new_partition = max(update_df$partition) + 1
            update_df$center[update_df$uniqueSequence == new_center_seq] = 1
            update_df$partition[update_df$uniqueSequence == new_center_seq] = new_partition
          }
          
          
        }
        #update list of center seqs 
        center_seqs = filter(update_df, center ==1) %>% select(., uniqueSequence) %>% unlist() %>% unname()
        #update list of isomiR seqs 
        isomiR_seqs = filter(update_df, center == 0 & count != 0) %>% select(., uniqueSequence) %>% unlist() %>% unname()
          
        #update master lambdas 
        for(seq in center_seqs){
          if(!(seq %in% names(master_lambdas))){
            new_alignments = lapply(isomiR_seqs, Biostrings::pairwiseAlignment, pattern = seq)
            names(new_alignments) = isomiR_seqs
            new_transitions = lapply(new_alignments, get_transitions)
            new_lambdas = lapply(new_transitions, compute_lambda, transition_probs = transition_probs)
            master_lambdas[[seq]] = new_lambdas
          }
        }
        cat("Updating partition membership \n")
        for(i in isomiR_seqs){
          l = lapply(master_lambdas, function(x) return(x[[i]])) %>% unlist()
          l = which(l == max(l))
          update_df$partition[update_df$uniqueSequence == i] = l
        }
        partition_df = update_df
        iter_partitioning = iter_partitioning + 1 
      } else{
        no_change = 1 
      }
    }
    else{
      cat("Following unique partitions currently exist in the data", uniq_partitions, "\n")
      #calculate raw p - values 
      cat("Calculating raw abundance p-values")
      raw_p_values = vector()
      for(j in uniq_partitions){
        n_j = filter(partition_df, center == 1 & partition == j) %>% select(., count) %>% unlist() %>% unname()
        cat("Observed read count for center sequence of partition", j, "is", n_j, "\n")
        partition_isomiRs = filter(partition_df, center == 0 & partition == j & count != 0) %>% select(., uniqueSequence) %>% unlist() %>% unname()
        cat("Partition", j, "has", length(partition_isomiRs), "sequences \n")
        if(length(partition_isomiRs) > 0){
        n_is = sapply(partition_isomiRs, function(x) filter(partition_df, uniqueSequence ==x) %>% select(., count) %>% unlist() %>% unname())
        names(n_is) = partition_isomiRs
        for(i in partition_isomiRs){
          lambda = master_lambdas[[j]][[i]]
          n_i = n_is[i]
          num = ppois(n_i, n_j*lambda, lower.tail = FALSE)
          denom = 1- dpois(0, n_j*lambda)
          p = c(num/denom)
          names(p)=i
          raw_p_values = c(raw_p_values, p)
          
        }
        }
      }
      cat("Adjusting p-values for multiple testing\n")
      adjusted_p_values = p.adjust(raw_p_values, method = "BH")
      
      significant_seqs = names(adjusted_p_values)[adjusted_p_values < OMEGA_A]
      
      #if at least one adjusted abundance p-value below user-defined threshold, must update partition membership by creating at least 1 new partition, IDing center sequence 
      if(length(significant_seqs)>0){
        #create copy of partition_df to update 
        cat("Creating new partitions where necessary \n")
        update_df = partition_df 
        for(j in uniq_partitions){
          partition_isomiRs = filter(partition_df, center == 0 & partition == j & count != 0) %>% select(., uniqueSequence) %>% unlist() %>% unname()
          significant_partition_isomiRs = partition_isomiRs[partition_isomiRs %in% significant_seqs]
          if(length(significant_partition_isomiRs) > 0){
            old_center_seq_count = filter(partition_df, center == 1 & partition == j) %>% select(., count) %>% unlist() %>% unname()
            #id new center seq 
            new_center_seq_df = filter(partition_df, uniqueSequence %in% significant_partition_isomiRs) %>% filter(., count == max(count))
            if(new_center_seq_df$count > OMEGA_A * old_center_seq_count){
              new_partition = max(update_df$partition) + 1 
              update_df$center[update_df$uniqueSequence == new_center_seq] = 1
              update_df$partition[update_df$uniqueSequence == new_center_seq] = new_partition
            }
            
          }
        }
        #update list of center sequences 
        center_seqs = filter(update_df, center == 1) %>% select(., uniqueSequence) %>% unlist() %>% unname()
        #update list of isomiR sequences 
        isomiR_seqs = filter(update_df, center == 0 & count != 0) %>% select(., uniqueSequence) %>% unlist() %>% unname()
        
        #update master_lambdas:
        for(seq in center_seqs){
          if(!(seq %in% names(master_lambdas))){
            new_alignments = lapply(isomiR_seqs, Biostrings::pairwiseAlignment, pattern = seq)
            names(new_alignments) = isomiR_seqs
            new_transitions = lapply(new_alignments, get_transitions)
            new_lambdas = lapply(new_transitions, compute_lambda, transition_probs=transition_probs)
            master_lambdas[[seq]] = new_lambdas
          }
        }
        cat("Letting isomiR sequences join newly formed partitions \n")
        for(i in isomiR_seqs){
          l = lapply(master_lambdas, function(x) return(x[[i]])) %>% unlist() 
          l = which(l == max(l)) %>% names()
          if(length(l) > 1){
            l = l[1]
          }
          partition = update_df$partition[update_df$uniqueSequence == l]
          update_df$partition[update_df$uniqueSequence == i] = partition
        }
        if(!(all.equal(partition_df$partition, update_df$partition) == TRUE)){
          partition_df = update_df 
          iter_partitioning = iter_partitioning + 1
          
        } else{
          no_change = 1
        }
        
        
      } else{
        no_change = 1 
        cat("All true isomiRs identified \n")
      }
      
      
      
      
    }
  }
  return(list(center_seqs=center_seqs, isomiR_seqs=isomiR_seqs, results_df=results_df, partition_df=partition_df, iter_partitioning=iter_partitioning, master_lambdas = master_lambdas))
}
```

```{r}
tst = estimate_isomiR_partition_membership(initial_partition_df, transition_probs=transition_probs, max_iter_partitioning = 1, OMEGA_A=0.05)

```

```{r}
master_lambdas = tst$master_lambdas
partition_df = tst$partition_df
raw_p_values = vector()
uniq_partitions = unique(partition_df$partition)
```

```{r}
for(j in uniq_partitions){
  cat("Working in partition", j, "\n")
  n_j = filter(partition_df, partition == j & center == 1) %>% select(., count) %>% unlist() %>% unname()
  cat("Observed read count of center sequence is", n_j, "\n")
  partition_isomiRs = filter(partition_df, partition == j & center == 0 & count != 0) %>% select(., uniqueSequence) %>% unlist() %>% unname()
  cat("There are", length(partition_isomiRs), "sequences in partition", j, "\n")
  n_is = sapply(partition_isomiRs, function(x) return(partition_df$count[partition_df$uniqueSequence == x]))
  names(n_is) = partition_isomiRs
  lambdas = master_lambdas[[partition_df$uniqueSequence[partition_df$center==1 & partition_df$partition == j]]]
  for(i in partition_isomiRs){
    lambda = lambdas[[i]]
    n_i = n_is[i]
    num = ppois(n_i, n_j*lambda, lower.tail = F)
    denom = 1-dpois(0, n_j*lambda)
    p = c(num/denom)
    names(p) = i
    raw_p_values = c(raw_p_values, p)
  }
}

adjusted_p_values = p.adjust(raw_p_values, method="BH")

significant_seqs = names(adjusted_p_values[adjusted_p_values < 0.05])

update_df = partition_df

for(j in uniq_partitions){
  cat("Determining if any sequences in partition", j, "should start their own partition \n")
  partition_isomiRs = filter(partition_df, partition == j & center == 0 & count != 0) %>% select(., uniqueSequence) %>% unlist() %>% unname()
  significant_partition_isomiRs = significant_seqs[significant_seqs %in% partition_isomiRs]
  if(length(significant_partition_isomiRs) > 0){
    cat("Length of significant_partition_isomiRs vector:", length(significant_partition_isomiRs), "\n")
    cat("Identifying new center sequence \n")
    new_center_seq = filter(partition_df, uniqueSequence %in% significant_partition_isomiRs) %>% filter(., count == max(count)) %>% select(., uniqueSequence) %>% unlist() %>% unname()
    new_center_seq = new_center_seq[1]
    cat("Creating new partition\n")
    new_partition = max(update_df$partition) + 1 
    cat(new_partition, "\n")
    update_df$partition[update_df$uniqueSequence == new_center_seq] = new_partition
    update_df$center[update_df$uniqueSequence == new_center_seq] = 1 
  } else{
    cat("No sequences to start new partition \n")
  }
}

table(update_df$partition)
filter(update_df, center == 1)

center_seqs = update_df$uniqueSequence[update_df$center == 1]
isomiR_seqs = update_df$uniqueSequence[update_df$center == 0 & update_df$count != 0]

for(seq in center_seqs){
  if(!(seq) %in% names(master_lambdas)){
    new_alignments = lapply(isomiR_seqs, Biostrings::pairwiseAlignment, pattern = seq)
    names(new_alignments) = isomiR_seqs
    new_transitions = lapply(new_alignments, get_transitions)
    new_lambdas = lapply(new_transitions, compute_lambda, transition_probs = transition_probs)
    master_lambdas[[seq]] = new_lambdas
  }
}

for(i in isomiR_seqs){
  #print(i)
  l = lapply(master_lambdas, function(x) return(x[[i]])) %>% unlist()
  l = which(l == max(l)) %>% names()
  if(length(l) > 1){
    l = l[1]
  }
  partition = update_df$partition[update_df$uniqueSequence == l]
  #print(length(partition))
  #print(length(update_df$partition[update_df$uniqueSequence==i]))
  update_df$partition[update_df$uniqueSequence == i] = partition
}

partition_df = update_df
center_seqs %in% names(master_lambdas)
```


```{r}

estimate_isomiR_partition_membership_v2 = function(partition_df, transition_probs, omega_A, max_grping_iterations){
  grping_iteration = 0 
  no_change = 0 
  while(grping_iteration < max_grping_iterations & no_change == 0){
    if(max(partition_df$partition) == 1){
      isomiR_seqs = filter(partition_df, center == 0 & count != 0) %>% select(., uniqueSequence) %>% unlist() %>% unname()
      center_seq = filter(partition_df, center ==1) %>% select(., uniqueSequence) %>% unlist() %>% unname()
      alignments = lapply(isomiR_seqs, Biostrings:: pairwiseAlignment, pattern = center_seq)
      names(alignments) = isomiR_seqs
      master_alignments = list(alignments)
      names(master_alignments) = center_seq
      transitions = lapply(alignments, get_transitions)
      master_transitions = list(center_seq=transitions)
      lambdas = lapply(transitions, compute_lambda, transition_probs=transition_probs)
      master_lambdas=list(center_seq=lambdas)
    }
    
    uniq_partitions = unique(partition_df$partition)
    
    raw_p_values = vector()
    for(j in uniq_partitions)
    
    grping_iteration = grping_iteration + 1
  }
  return(list(master_alignments=master_alignments, master_transitions=master_transitions, master_lambdas=master_lambdas))
}

```

```{r}
tst = estimate_isomiR_partition_membership_v2(initial_partition_df, transition_probs, 0.05, 1)
```

```{r}
new_transition_probs = estimate_transition_probs(partition_df)

```

```{r}
tst_2 = estimate_isomiR_partition_membership(partition_df, new_transition_probs, 1, 0.05)

```

Algorithm is going to have 2 steps - the transition probability estimation step that acts as the expectation step in a traditional EM algorithm and the partitioning step that acts like the maximization step in a traditional EM algorithm. We will iterate between the two steps until we reach a point where no new partitions are formed and no more isomiR sequences are moving between partitions. \n

We've already done a lot of work on the second step, the partitioning step as I would argue it's the  harder of the two steps. Now, we need to work on the transition probabilities step. \n \n
I think it makes the most sense to have a separate function perform transition probability estimation and then have the output of that function be one of the inputs of the partitioning function. 


# Step 1: Transition probability estimation
```{r}
# 0 - initialize partition_df object since this step will work from that one
partition_df = cbind(rowdata, count = countdata[,2]) %>% data.frame() %>% filter(., miRNA_name == test_miRNA)
head(partition_df)

#there are duplicate rows in the  data for this miRNA so we need to condense them and sum read counts for those guys:
unique_isomiRs = unique(partition_df$uniqueSequence)
cat("Number of unique isomiR sequences mapping to miRNA", length(unique_isomiRs), "\n")
cat("Number of rows in partition_df:", nrow(partition_df), "\n")

mat = partition_df[1,]
for(seq in unique_isomiRs[2:length(unique_isomiRs)]){
  sub_df = filter(partition_df, uniqueSequence == seq)
  #print(sub_df)
  s = seq
  #print(s)
  n = sub_df$miRNA_name[1]
  #print(n)
  c = sum(sub_df$count)
  #print(c)
  mat = rbind(mat, c(s,n,c))
  #print(mat)
  #mat = data.frame(mat)
}
#mat = distinct(mat)
mat$count = as.numeric(mat$count)
partition_df = mat 
partition_df$partition = rep(1, nrow(partition_df))
partition_df$center = rep(0, nrow(partition_df))

#pick a center sequence for the initial partition
initial_center_seq = filter(partition_df, count == max(count)) %>% select(., uniqueSequence) %>% unlist() %>% unname()
partition_df$center[partition_df$uniqueSequence == initial_center_seq] = 1 

head(partition_df)
filter(partition_df, center == 1)

# 1 - initialize transition counts matrix 
transition_counts = initialize_transition_counts_matrix(5)
print(transition_counts)

# 2 - Get currently existing unique partitions
unique_partitions = unique(partition_df$partition)
#for each partition:
for(j in unique_partitions){
  #a. ID center sequence
  center_seq = filter(partition_df, partition == j & center == 1) %>% select(., uniqueSequence) %>% unlist() %>% unname()
  #b. ID isomiR sequences in partition
  partition_isomiRs = filter(partition_df, partition == j & center == 0 & count != 0) %>% select(., uniqueSequence) %>% unlist() %>% unname()
  #c. pairwise alignments between center seq and isomiR seqs
  alignments = lapply(partition_isomiRs, Biostrings::pairwiseAlignment, pattern = center_seq)
  names(alignments) = partition_isomiRs
  #d. transitions from alignments 
  transitions = lapply(alignments, get_transitions)
  #e. for each transition, get individual transitions along each position of alignment
  for(t in transitions){
    alignment_length = ncol(t)
    for(i in 1:alignment_length){
      trns = get_transition_at_idx(i, t)
      x=trns$x
      y=trns$y
      if((i == 1) & (x != "-") & (y !=  "-")){
        transition_counts["-", "-"] = transition_counts["-", "-"]+1
        transition_counts[x,y] = transition_counts[x,y]+1
      }
      if((i == alignment_length) & (x != "-") & (y != "-")){
        transition_counts["-", "-"] = transition_counts["-", "-"]+1
        transition_counts[x,y] = transition_counts[x,y]+1
      } else{
        transition_counts[x,y] = transition_counts[x,y]+1
      }
      
    }
  }
}

print(transition_counts)

transition_probs = transition_counts
for(i in 1:nrow(transition_probs)){
  transition_probs[i,] = transition_probs[i,]/sum(transition_probs[i,])
}

print(transition_probs)

saveRDS(transition_probs, "/scratch/hswan/thesis_isomiR_count_denoising/transition_probs.Rds")
saveRDS(partition_df, "/scratch/hswan/thesis_isomiR_count_denoising/initial_partition_df.Rds")
```

# Step 2 - Partitioning estimation
```{r}
max_iter = 10
OMEGA_A=0.05

iter = 0
no_change = 0
```

```{r}
while(iter < max_iter & no_change == 0){
  unique_partitions = unique(partition_df$partition)
  print(length(unique_partitions))
  if(length(unique_partitions) == 1){
    center_seq = filter(partition_df, center == 1) %>% select(., uniqueSequence)  %>% unlist() %>% unname()
    cat("Center seq is", center_seq, "\n")
    isomiR_seqs = filter(partition_df, center == 0 & count != 0) %>% select(., uniqueSequence) %>% unlist()  %>% unname()
    #alignments
    cat("Getting alignments \n")
    alignments = lapply(isomiR_seqs, Biostrings::pairwiseAlignment, pattern = center_seq)
    names(alignments)  = isomiR_seqs
    #transitions
    cat("Getting transitions\n")
    transitions = lapply(alignments, get_transitions)
    #lambdas
    cat("Calculating lambdas\n")
    lambdas = lapply(transitions, compute_lambda, transition_probs=transition_probs)
    master_lambdas = list()
    master_lambdas[[center_seq]] = lambdas
    cat("Calculating abundance p_values\n")
    #abundance p values:
    n_j = filter(partition_df, uniqueSequence  == center_seq) %>% select(., count) %>% unlist() %>% unname()
    raw_p_values = vector()
    for(i in isomiR_seqs){
      lambda = master_lambdas[[center_seq]][[i]]
      n_i = filter(partition_df, uniqueSequence  == i) %>% select(., count) %>% unlist() %>% unname()
      num = ppois(n_i, n_j*lambda, lower.tail=FALSE)
      denom  = 1-dpois(0, n_j*lambda)
      p = c(num/denom)
      names(p) = i
      raw_p_values = c(raw_p_values, p)
    }
    cat("Getting hypothesis testing results \n")
    results_df = data.frame(raw_p_values)
    results_df$adjusted_p_values = p.adjust(raw_p_values, method="BH")
    results_df$significant = rep(0, nrow(results_df))
    results_df$significant[results_df$adjusted_p_values < OMEGA_A] = 1 
    
    cat("Determining if we need to create a new partition\n")
    significant_seqs = row.names(results_df[results_df$significant==1,])
    update_df = partition_df
    #if at least one seq in initial partition has significant p-value, start new partition
    if(length(significant_seqs) != 0){
      new_center_seq = filter(partition_df, uniqueSequence %in% significant_seqs) %>% filter(., count == max(count)) %>% select(., uniqueSequence) %>% unlist() %>% unname()
      new_partition = max(update_df$partition) + 1
      update_df$center[update_df$uniqueSequence == new_center_seq] = 1
      update_df$partition[update_df$uniqueSequence == new_center_seq] = new_partition
      #update center sequences list 
      center_seqs = filter(update_df, center == 1) %>% select(., uniqueSequence) %>% unlist() %>% unname()
      isomiR_seqs = filter(update_df, center == 0 & count !=0) %>% select(., uniqueSequence) %>% unlist() %>% unname()
      for(seq in center_seqs){
        if(!(seq %in% names(master_lambdas))){
          new_alignments = lapply(isomiR_seqs, Biostrings::pairwiseAlignment, pattern = seq)
          names(new_alignments) = isomiR_seqs
          new_transitions = lapply(new_alignments, get_transitions)
          new_lambdas = lapply(new_transitions, compute_lambda, transition_probs=transition_probs)
          master_lambdas[[seq]] = new_lambdas
        }
      }
      cat("Updating partition membership, letting some isomiR sequences move to newly created partition\n")
      for(seq in isomiR_seqs){
        l = lapply(master_lambdas, function(x) return(x[[seq]])) %>% unlist()
        l = which(l == max(l))
        update_df$partition[update_df$uniqueSequence == seq] = l

      }
      partition_df = update_df
    } else{
      no_change = 1 
    }
    
    cat("Iter", iter, "done\n")
    iter = iter + 1
    cat("Beginning iter", iter,  "\n")
  } else{
    raw_p_values  = vector()
    for(j in unique_partitions){
      center_seq = filter(partition_df, partition ==  j & center == 1) %>% select(., uniqueSequence) %>% unlist() %>% unname()
      cat("Center sequence of partition", j, "is", center_seq, "\n")
      partition_isomiRs = filter(partition_df, partition == j & center == 0 & count != 0) %>% select(., uniqueSequence) %>% unlist() %>% unname()
      n_j = filter(partition_df, uniqueSequence == center_seq) %>% select(., count) %>% unlist() %>% unname()
      cat("Observed read count of center sequence is",  n_j, "\n")
      if(length(partition_isomiRs) > 0){
      for(i in partition_isomiRs){
        lambda = master_lambdas[[center_seq]][[i]]
        n_i = filter(partition_df, uniqueSequence ==i) %>% select(., count) %>% unlist() %>% unname()
        num = ppois(n_i, n_j*lambda, lower.tail=FALSE)
        denom = 1-dpois(0, n_j*lambda)
        p=c(num/denom)
        names(p) = i
        raw_p_values = c(raw_p_values, p)
      }
      }
    }
    cat("Getting results of hypothesis testing \n")
    results_df = data.frame(raw_p_values)
    results_df$adjusted_p_values = p.adjust(raw_p_values)
    results_df$significant = rep(0, nrow(results_df))
    results_df$significant[results_df$adjusted_p_values < OMEGA_A] = 1
    
    cat("Determining which existing partitions, if any, have sequences that should start their own partition\n")
    
    significant_seqs = row.names(filter(results_df, significant == 1)) 
    #make copy of partition_df for updating
    update_df = partition_df
    
    if(length(significant_seqs) > 0){
      for(j in unique_partitions){
        partition_isomiRs = filter(partition_df, partition == j & center == 0 & count !=0) %>% select(., uniqueSequence) %>% unlist() %>% unname()
        partition_significant_seqs = significant_seqs[significant_seqs %in% partition_isomiRs]
        if(length(partition_significant_seqs) > 0){
          #ID new center seq
          new_center_seq = filter(partition_df, uniqueSequence %in% partition_significant_seqs) %>% filter(., count == max(count)) %>% select(., uniqueSequence)  %>% unlist() %>% unname()
          new_center_seq = new_center_seq[1]
          #start new grp
          new_partition = max(update_df$partition) + 1 
          update_df$partition[update_df$uniqueSequence == new_center_seq] = new_partition
          update_df$center[update_df$uniqueSequence == new_center_seq] = 1 
          
        }
      }
      #update list of center sequences
      center_seqs = filter(update_df, center == 1) %>% select(., uniqueSequence) %>% unlist() %>% unname()
      #update list of isomiR sequences
      isomiR_seqs = filter(update_df, center == 0 & count != 0) %>% select(., uniqueSequence) %>% unlist() %>% unname()
      #align isomiR sequences to newly identified center sequences, then calculate lambdas so we can update grp membership
      for(seq in center_seqs){
        if(!(seq %in% names(master_lambdas))){
          new_alignments = lapply(isomiR_seqs, Biostrings::pairwiseAlignment, pattern = seq)
          names(new_alignments) = isomiR_seqs
          new_transitions = lapply(new_alignments, get_transitions)
          new_lambdas = lapply(new_transitions, compute_lambda, transition_probs=transition_probs)
          master_lambdas[[seq]] = new_lambdas
        }
        
      }
      #update partition membership
      for(i in isomiR_seqs){
        l = lapply(master_lambdas, function(x) return(x[[i]])) %>% unlist()
        l = which(l==max(l))
        update_df$partition[update_df$uniqueSequence  == i] = l
      }
      partition_df=update_df
      cat("Finishing iteration", iter, "\n")
      iter = iter + 1
      cat("Beginning iteration", iter, "\n")
    } else{
      cat("No new partitions being formed. No change from last iteration \n")
      no_change = 1
    }
  }
  
}

```