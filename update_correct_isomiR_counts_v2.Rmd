---
title: "Update correct_isomiR_counts_v2 function"
author: "Hannah Swan"
date: "November 5, 2024"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Clear environment:
```{r}
rm(list=ls())
```

Load necessary R packages:
```{r}
library(DESeq2)
library(Biostrings)
library(tidyverse)

```

Load necessary functions:
```{r}
source("/scratch/hswan/thesis_isomiR_count_denoising/correct_technical_length_variant_functions.R")
```

Load Ernesto's dataset:
```{r}
load("/scratch/mmccall2_lab/miRNA_reference/Rdata/summarized_experiment_isomiR.RData")
isomiR_se_object = se_object 
rm(se_object)
```

Create rowdata, countdata objects:
```{r}
rowdata = rowData(isomiR_se_object) %>% data.frame()
colnames(rowdata) = c("uniqueSequence", "miRNA_name")

countdata = isomiR_se_object@assays@data$counts %>% data.frame()
colnames(countdata) = str_remove_all(colnames(countdata), "X")

head(rowdata)
head(countdata)
```

### 1st ITERATION OF OUTER LOOP
```{r}
#initialize partition_df, first need to pick miRNA for testing 
unique_mirnas = unique(rowdata$miRNA_name)
num_isomiRs = sapply(unique_mirnas, function(x) return(nrow(filter(rowdata, miRNA_name == x))))

miRNAs_for_testing = unique_mirnas[num_isomiRs < 1000]
tst_miRNA = miRNAs_for_testing[2]
cat("miRNA we will use for testing is", tst_miRNA, "\n")

partition_df = cbind(rowdata, countdata[,"1L"]) %>% data.frame() %>% filter(., miRNA_name == tst_miRNA)
colnames(partition_df)[3] = 'count'
head(partition_df)
partition_df$partition = rep(1, nrow(partition_df))
partition_df$center = rep(0, nrow(partition_df))
partition_df$center[partition_df$count == max(partition_df$count)] = 1

filter(partition_df, center == 1)

center_sequence = filter(partition_df, center == 1) %>% select(., uniqueSequence) %>% unlist()
isomiR_sequences = filter(partition_df, count!=0 & center == 0) %>% select(., uniqueSequence) %>% unlist()

alignments = lapply(isomiR_sequences, Biostrings::pairwiseAlignment, pattern = center_sequence)
names(alignments) = isomiR_sequences
transitions = lapply(alignments, get_transitions)

transition_counts = initialize_transition_counts_matrix(5)
print(transition_counts)

for(t in transitions){
  alignment_length = ncol(t)
  for(i in 1:alignment_length){
    trns = get_transition_at_idx(i, t)
    x = trns$x
    y = trns$y
    if(i == 1 & x != "-" & y!= "-"){
      transition_counts["-", "-"] = transition_counts["-", "-"]+1
    } else if(i == alignment_length & x != "-" & y!="-"){
      transition_counts["-", "-"] = transition_counts["-", "-"] + 1 
    } else {
      transition_counts[x,y] = transition_counts[x,y] + 1
    }
  }
}

print(transition_counts)

transition_probs = transition_counts
for(i in 1:nrow(transition_counts)){
  transition_probs[i,] = transition_probs[i,]/sum(transition_probs[i,])
}

transition_probs

```
### 1st ITERATION OF INNER LOOP
```{r}
lambdas = lapply(transitions, compute_lambda, transition_probs=transition_probs)
head(lambdas)

raw_p_values = vector()
for(j in unique(partition_df$partition)){
  n_j = filter(partition_df, partition == j & center == 1) %>% select(., count) %>% unlist()
  cat("Observed read count for center sequence of partition", j, "is", n_j, "\n")
  partition_isomiRs = filter(partition_df, partition == j & center == 0 & count != 0) %>% select(., uniqueSequence) %>% unlist()
  for(i in partition_isomiRs){
    n_i = filter(partition_df, uniqueSequence == i) %>% select(., count) %>% unlist() %>% unname()
    lambda = lambdas[[i]]
    num = ppois(n_i, n_j*lambda, lower.tail=FALSE)
    denom = 1-dpois(0, n_j*lambda)
    p=c(num/denom)
    names(p) = i
    raw_p_values = c(raw_p_values, p)
  }
}

head(raw_p_values)
OMEGA_A=0.05
results_df = data.frame(raw_p_values)
results_df$seq = row.names(results_df)
results_df$adjusted_p_values = p.adjust(raw_p_values, method="BH")
results_df$significant = rep(0, nrow(results_df))
results_df$significant[results_df$adjusted_p_values < OMEGA_A] = 1
row.names(results_df)=NULL
head(results_df)

#for each partition, ID a new center sequence 
update_df = partition_df
significant_isomiRs = filter(results_df, significant == 1) %>% select(., seq) %>% unlist()
for(j in unique(partition_df$partition)){
  new_center_seq = filter(partition_df, partition == j & uniqueSequence %in% significant_isomiRs) %>% filter(., count == max(count)) %>% select(., uniqueSequence) %>% unlist() %>% unname()
  new_center_seq = new_center_seq[1]
  update_df$center[update_df$uniqueSequence == new_center_seq] = 1
  new_partition = max(update_df$partition) + 1
  update_df$partition[update_df$uniqueSequence == new_center_seq] = new_partition
}


#for each isomiR sequence, we already have alignment between the original center sequence for initial partition and isomiR
#we need alignment between each isomiR sequence and new_center sequence to calculate new lambdas 
isomiR_sequences = isomiR_sequences[isomiR_sequences != new_center_seq]
new_alignments = lapply(isomiR_sequences, Biostrings::pairwiseAlignment, pattern = new_center_seq)
names(new_alignments)=isomiR_sequences 
new_transitions = lapply(new_alignments, get_transitions)
new_lambdas = lapply(new_transitions, compute_lambda, transition_probs=transition_probs)

#now update partitioning:
for(seq in isomiR_sequences){
  if(lambdas[[seq]] < new_lambdas[[seq]]){
    update_df$partition[update_df$uniqueSequence == seq] = new_partition
  }
}

table(update_df$partition)



```

### 2nd ITERATION OF INNER LOOP 
```{r}
master_lambdas = list(lambdas, new_lambdas)
names(master_lambdas) = c(center_sequence, new_center_seq)

raw_p_values = vector()
for(j in unique(update_df$partition)){
  cat("Working in partition", j, "\n")
  n_j = filter(update_df, partition==j & center == 1) %>% select(., count) %>% unlist()
  center_seq = filter(update_df, partition==j&center==1) %>% select(., uniqueSequence) %>% unlist()
  cat("Observed read count of the center sequence for partition", j, "is", n_j, "\n")
  isomiR_seqs = filter(update_df, partition == j & center == 0 & count !=0) %>% select(., uniqueSequence) %>% unlist()
  lambdas = master_lambdas[[center_seq]]
  for(i in isomiR_seqs){
    lambda = lambdas[[i]]
    n_i = update_df$count[update_df$uniqueSequence==i]
    num = ppois(n_i, n_j*lambda, lower.tail=FALSE)
    denom = 1-dpois(0, n_j*lambda)
    p = c(num/denom)
    names(p) = i
    raw_p_values = c(p, raw_p_values)
  }
}

results_df = data.frame(raw_p_values)
results_df$adjusted_p_values = p.adjust(raw_p_values, method="BH")
results_df$significant = rep(0, nrow(results_df))
results_df$significant[results_df$adjusted_p_values < OMEGA_A] = 1
results_df$seq = row.names(results_df)
row.names(results_df)=NULL
head(results_df)

#for each existing partition, ID a new center sequence 
significant_seqs = results_df$seq[results_df$significant==1]

for(j in unique(update_df$partition)) {
  new_center_df = filter(update_df, center == 0 & partition == j) %>% filter(., uniqueSequence %in% significant_seqs) 
  if(nrow(new_center_df) > 0){
    new_center = filter(new_center_df, count == max(count)) %>% select(., uniqueSequence) %>% unlist()
    new_center = new_center[1]
    new_partition = max(update_df$partition) + 1
    update_df$center[update_df$uniqueSequence == new_center] = 1
    update_df$partition[update_df$uniqueSequence == new_center] = new_partition
  }
  
  
}

center_seqs = update_df$uniqueSequence[update_df$center == 1]
isomiR_seqs = update_df$uniqueSequence[update_df$center == 0 & update_df$count != 0]
#for each center sequence:
#first, check to see if center sequence already has an element in master_lambdas list
#if it doesn't
for(seq in center_seqs){
  if(!(seq %in% names(master_lambdas))){
    new_alignments = lapply(isomiR_seqs, Biostrings::pairwiseAlignment, pattern = seq)
    names(new_alignments) = isomiR_seqs
    new_transitions = lapply(new_alignments, get_transitions)
    new_lambdas = lapply(new_transitions, compute_lambda, transition_probs=transition_probs)
    master_lambdas[[seq]] = new_lambdas
  }
}

#for each isomiR sequence, need to decide what partition it belongs to:
l = lapply(master_lambdas, function(x) return(x[[isomiR_seqs[1]]])) %>% unlist() 
l = which(l==max(l))
update_df$partition[update_df$uniqueSequence == isomiR_seqs[1]] = l

#update group membership step:
for(seq in isomiR_seqs){
  l = lapply(master_lambdas, function(x) return(x[[seq]])) %>% unlist()
  l = which(l==max(l))
  update_df$partition[update_df$uniqueSequence == seq] = l
}

#update_df becomes partition_df:
partition_df=update_df
#recalculate abundance p_values:
raw_p_values = vector()
for(j in unique(partition_df$partition)){
  cat("Working in partition", j, "\n")
  n_j = filter(partition_df, partition == j & center == 1) %>% select(., count) %>% unlist() %>% unname()
  cat("Observed read count for center sequence of partition", j, "is", n_j, "\n")
  partition_isomiRs = filter(partition_df, partition == j & center == 0 & count != 0) %>% select(., uniqueSequence) %>% unlist() %>% unname()
  for(i in partition_isomiRs){
    lambda = master_lambdas[[j]][[i]]
    n_i = filter(partition_df, uniqueSequence ==i) %>% select(., count) %>% unlist() %>% unname()
    num = ppois(n_i, n_j*lambda, lower.tail=FALSE)
    denom = 1-dpois(0, n_j*lambda)
    p = c(num/denom)
    names(p) = i
    raw_p_values = c(raw_p_values, p)
  }
  
}

results_df = data.frame(raw_p_values)
results_df$adjusted_p_values = p.adjust(raw_p_values, method="BH")
results_df$significant = rep(0, nrow(results_df))
results_df$significant[results_df$adjusted_p_values < OMEGA_A] = 1
head(results_df)

significant_seqs = row.names(results_df[results_df$significant==1,])

#for each partition, decide if we need to create a new partition from it:
for(j in unique(partition_df$partition)){
  significant_partition_isomiRs = filter(partition_df, partition == j & uniqueSequence %in% significant_seqs)
  if(length(significant_partition_isomiRs) >0){
    new_center = filter(significant_partition_isomiRs, count == max(count))%>%  select(., uniqueSequence) %>% unlist()
    new_center = new_center[1]
    print(new_center)
    new_partition = max(update_df$partition) + 1 
    update_df$center[update_df$uniqueSequence == new_center] = 1
    update_df$partition[update_df$uniqueSequence == new_center] = new_partition 
  }
}

table(update_df$partition)

center_seqs = update_df$uniqueSequence[update_df$center == 1]
isomiR_seqs = update_df$uniqueSequence[update_df$center == 0 & update_df$count != 0]

for(seq in center_seqs){
  if(!(seq %in% names(master_lambdas))){
  new_alignments = lapply(isomiR_seqs, Biostrings::pairwiseAlignment, pattern = seq)
  new_transitions = lapply(new_alignments, get_transitions)
  new_lambdas = lapply(new_transitions, compute_lambda, transition_probs=transition_probs)
  master_lambdas[[seq]] = new_lambdas
  }
  
}

#update grp membership 
for(seq in isomiR_seqs){
  l = lapply(master_lambdas, function(x) return(x[[seq]])) %>% unlist()
  l = which(l == max(l))
  update_df$partition[update_df$uniqueSequence == seq] = l
}

table(update_df$partition)
partition_df = update_df

```


### 3rd ITERATION OF INNER LOOP
```{r}
#calculate raw p-values
raw_p_values = vector()
for(j in unique(partition_df$partition)){
  cat("Working in partition", j, "\n")
  n_j = filter(partition_df, partition == j & center == 1) %>% select(., count) %>% unlist() %>% unname()
  cat("Observed read count of center sequence in partition", j, "is", n_j, "\n")
  partition_isomiRs = filter(partition_df, partition == j & center == 0 & count != 0) %>% select(., uniqueSequence) %>% unlist()
  if(length(partition_isomiRs) > 0){
    for(i in partition_isomiRs){
      n_i = partition_df$count[partition_df$uniqueSequence == i]
      lambda = master_lambdas[[j]][[i]]
      num = ppois(n_i, n_j*lambda, lower.tail=FALSE)
      denom = 1-dpois(0, n_j*lambda)
      p=c(num/denom)
      names(p) = i
      raw_p_values = c(raw_p_values, p)
    }
  }
}

results_df = data.frame(raw_p_values)
results_df$adjusted_p_values = p.adjust(raw_p_values, method='BH')
results_df$significant = rep(0, nrow(results_df))
results_df$significant[results_df$adjusted_p_values < OMEGA_A]=1
head(results_df)


significant_seqs = row.names(results_df[results_df$significant==1,])

#figure out which partitions are going to produce a new group:
update_df = partition_df
for(j in unique(partition_df$partition)){
  significant_partition_isomiRs = filter(partition_df, uniqueSequence %in% significant_seqs & partition == j) %>% select(., uniqueSequence) %>% unlist()
  if(length(significant_partition_isomiRs) > 0){
    new_center_df = filter(partition_df, uniqueSequence %in% significant_partition_isomiRs) %>% filter(., count == max(count)) 
    new_center = new_center_df$uniqueSequence[1]
    new_partition = max(update_df$partition) + 1
    update_df$center[update_df$uniqueSequence == new_center] = 1
    update_df$partition[update_df$uniqueSequence == new_center] = new_partition
  }
}

isomiR_seqs = update_df$uniqueSequence[update_df$center == 0 & update_df$count != 0]
center_seqs = update_df$uniqueSequence[update_df$center == 1]


for(seq in center_seqs){
  if(!(seq %in% names(master_lambdas))){
    new_alignments = lapply(isomiR_seqs, Biostrings::pairwiseAlignment, pattern = seq)
    names(new_alignments) = isomiR_seqs
    new_transitions = lapply(new_alignments, get_transitions)
    new_lambdas = lapply(new_transitions, compute_lambda, transition_probs=transition_probs)
    master_lambdas[[seq]] = new_lambdas
  }
}
  

#update group membership
for(seq in isomiR_seqs){
  l = lapply(master_lambdas, function(x) return(x[[seq]])) %>% unlist()
  l = which(l==max(l))
  if(length(l) > 1){
    l = l[1]
  }
  update_df$partition[update_df$uniqueSequence==seq] = l
}

table(update_df$partition)

```